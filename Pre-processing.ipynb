{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "from scipy import sparse\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling 100000 data points\n",
    "project_data = pd.read_csv('train_data.csv').sample(n=25000)\n",
    "resource_data = pd.read_csv('resources.csv')\n",
    "\n",
    "price_data = resource_data.groupby('id').agg({'price':'sum', 'quantity':'sum'}).reset_index()\n",
    "project_data = pd.merge(project_data, price_data, on='id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = project_data['project_is_approved'].values\n",
    "X = project_data.drop(['project_is_approved'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 18) (20000,)\n",
      "(5000, 18) (5000,)\n"
     ]
    }
   ],
   "source": [
    "# train test cv split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, stratify=y)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decontracted(phrase):\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords= ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
    "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
    "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
    "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
    "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
    "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
    "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
    "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
    "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
    "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
    "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
    "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
    "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
    "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
    "            'won', \"won't\", 'wouldn', \"wouldn't\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    preprocessed_text = []\n",
    "    for sent in text:\n",
    "        sent = decontracted(sent)\n",
    "        sent = sent.replace('\\\\r', ' ')\n",
    "        sent = sent.replace('\\\\n', ' ')\n",
    "        sent = sent.replace('\\\\\"', ' ')\n",
    "        sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "        sent = ' '.join(e for e in sent.split() if e.lower() not in stopwords)\n",
    "        preprocessed_text.append(sent.lower().strip())\n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list_bow = []\n",
    "feature_list_tfidf = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_table(X_train, y_train, X_test, col):\n",
    "    lst = []\n",
    "    categories = X_train[col].unique()\n",
    "    for i in categories:\n",
    "        tot = X_train[(X_train[col]==i)][col].count()\n",
    "        cat_0 = (X_train[(X_train[col]==i) & (y_train==0)][col].count())/tot\n",
    "        cat_1 = (X_train[(X_train[col]==i) & (y_train==1)][col].count())/tot\n",
    "        lst.append([i, cat_0, cat_1])\n",
    "    response_table = pd.DataFrame(lst, columns = ['categories', 'cat_0', 'cat_1'])\n",
    "    response_table.set_index('categories', inplace=True)\n",
    "    \n",
    "    df_train = pd.DataFrame()\n",
    "    df_train['cat_0'] = list(map(lambda cat: response_table.loc[cat]['cat_0'], X_train[col].values))\n",
    "    df_train['cat_1'] = list(map(lambda cat: response_table.loc[cat]['cat_1'], X_train[col].values))\n",
    "    \n",
    "    df_test = pd.DataFrame()\n",
    "    df_test['cat_0'] = list(map(lambda cat: response_table.loc[cat]['cat_0'] if(cat in categories) else 0.5 , X_test[col].values))\n",
    "    df_test['cat_1'] = list(map(lambda cat: response_table.loc[cat]['cat_1'] if(cat in categories) else 0.5 , X_test[col].values))\n",
    "    \n",
    "    return response_table, df_train, df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. teacher_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 5) (20000,)\n",
      "(5000, 5) (5000,)\n"
     ]
    }
   ],
   "source": [
    "def preprocess_teacher_prefix(df):\n",
    "    df['teacher_prefix'] = df['teacher_prefix'].fillna('Mrs.')\n",
    "    df['teacher_prefix'] = df['teacher_prefix'].str.replace('.', '')\n",
    "    df['teacher_prefix'] = df['teacher_prefix'].str.lower()\n",
    "\n",
    "preprocess_teacher_prefix(X_train)\n",
    "preprocess_teacher_prefix(X_test)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(X_train['teacher_prefix'].values)\n",
    "\n",
    "X_train_teacher_ohe = vectorizer.transform(X_train['teacher_prefix'].values)\n",
    "X_test_teacher_ohe = vectorizer.transform(X_test['teacher_prefix'].values)\n",
    "\n",
    "feature_list_bow.extend(vectorizer.get_feature_names())\n",
    "feature_list_tfidf.extend(vectorizer.get_feature_names())\n",
    "\n",
    "print(X_train_teacher_ohe.shape, y_train.shape)\n",
    "print(X_test_teacher_ohe.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_prefix_rt, teacher_prefix_train_df, teacher_prefix_test_df = get_response_table(X_train, y_train, X_test, 'teacher_prefix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. school_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 51) (20000,)\n",
      "(5000, 51) (5000,)\n"
     ]
    }
   ],
   "source": [
    "def preprocess_school_state(df):\n",
    "    df['school_state'] = df['school_state'].str.lower()\n",
    "\n",
    "preprocess_school_state(X_train)\n",
    "preprocess_school_state(X_test)\n",
    "\n",
    "vectorizer = CountVectorizer(binary=True)\n",
    "vectorizer.fit(X_train['school_state'].values)\n",
    "\n",
    "X_train_state_ohe = vectorizer.transform(X_train['school_state'].values)\n",
    "X_test_state_ohe = vectorizer.transform(X_test['school_state'].values)\n",
    "\n",
    "feature_list_bow.extend(vectorizer.get_feature_names())\n",
    "feature_list_tfidf.extend(vectorizer.get_feature_names())\n",
    "\n",
    "print(X_train_state_ohe.shape, y_train.shape)\n",
    "print(X_test_state_ohe.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "school_state_rt, school_state_train_df, school_state_test_df = get_response_table(X_train, y_train, X_test,'school_state')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. project_grade_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 4) (20000,)\n",
      "(5000, 4) (5000,)\n"
     ]
    }
   ],
   "source": [
    "def preprocess_project_grade_category(df):\n",
    "    df['project_grade_category'] = df['project_grade_category'].str.replace(' ', '_')\n",
    "    df['project_grade_category'] = df['project_grade_category'].str.replace('-', '_')\n",
    "    df['project_grade_category'] = df['project_grade_category'].str.lower()\n",
    "\n",
    "preprocess_project_grade_category(X_train)\n",
    "preprocess_project_grade_category(X_test)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(X_train['project_grade_category'].values)\n",
    "\n",
    "X_train_grade_ohe = vectorizer.transform(X_train['project_grade_category'].values)\n",
    "X_test_grade_ohe = vectorizer.transform(X_test['project_grade_category'].values)\n",
    "\n",
    "feature_list_bow.extend(vectorizer.get_feature_names())\n",
    "feature_list_tfidf.extend(vectorizer.get_feature_names())\n",
    "\n",
    "print(X_train_grade_ohe.shape, y_train.shape)\n",
    "print(X_test_grade_ohe.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_grade_category_rt, project_grade_category_train_df, project_grade_category_test_df = get_response_table(X_train, y_train, X_test,'project_grade_category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. project_subject_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 18) (20000,)\n",
      "(5000, 18) (5000,)\n"
     ]
    }
   ],
   "source": [
    "def preprocess_project_subject_categories(df):\n",
    "    df['project_subject_categories'] = project_data['project_subject_categories'].str.replace(' The', '')\n",
    "    df['project_subject_categories'] = project_data['project_subject_categories'].str.replace(' ', '')\n",
    "    df['project_subject_categories'] = project_data['project_subject_categories'].str.replace('&', '_')\n",
    "    df['project_subject_categories'] = project_data['project_subject_categories'].str.replace(',', '_')\n",
    "    df['project_subject_categories'] = project_data['project_subject_categories'].str.lower()\n",
    "\n",
    "preprocess_project_subject_categories(X_train)\n",
    "preprocess_project_subject_categories(X_test)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(X_train['project_subject_categories'].values)\n",
    "\n",
    "X_train_subject_ohe = vectorizer.transform(X_train['project_subject_categories'].values)\n",
    "X_test_subject_ohe = vectorizer.transform(X_test['project_subject_categories'].values)\n",
    "\n",
    "feature_list_bow.extend(vectorizer.get_feature_names())\n",
    "feature_list_tfidf.extend(vectorizer.get_feature_names())\n",
    "\n",
    "print(X_train_subject_ohe.shape, y_train.shape)\n",
    "print(X_test_subject_ohe.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_subject_categories_rt, project_subject_categories_train_df, project_subject_categories_test_df = get_response_table(X_train, y_train, X_test,'project_subject_categories')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. project_subject_subcategories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 328) (20000,)\n",
      "(20000, 328) (5000,)\n"
     ]
    }
   ],
   "source": [
    "def preprocess_project_subject_subcategories(df):\n",
    "    df['project_subject_subcategories'] = df['project_subject_subcategories'].str.replace(' The', '')\n",
    "    df['project_subject_subcategories'] = df['project_subject_subcategories'].str.replace(' ','')\n",
    "    df['project_subject_subcategories'] = df['project_subject_subcategories'].str.replace('&', '_')\n",
    "    df['project_subject_subcategories'] = df['project_subject_subcategories'].str.replace(',', '_')\n",
    "    df['project_subject_subcategories'] = df['project_subject_subcategories'].str.lower()\n",
    "\n",
    "preprocess_project_subject_subcategories(X_train)\n",
    "preprocess_project_subject_subcategories(X_test)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(X_train['project_subject_subcategories'].values)\n",
    "\n",
    "X_train_subject_subcategories_ohe = vectorizer.transform(X_train['project_subject_subcategories'].values)\n",
    "X_test_subject_subcategories_ohe = vectorizer.transform(X_test['project_subject_subcategories'].values)\n",
    "\n",
    "feature_list_bow.extend(vectorizer.get_feature_names())\n",
    "feature_list_tfidf.extend(vectorizer.get_feature_names())\n",
    "\n",
    "print(X_train_subject_subcategories_ohe.shape, y_train.shape)\n",
    "print(X_train_subject_subcategories_ohe.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_subject_subcategories_rt, project_subject_subcategories_train_df, project_subject_subcategories_test_df = get_response_table(X_train, y_train, X_test,'project_subject_subcategories')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. essay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 8369) (20000,)\n",
      "(5000, 8369) (5000,)\n"
     ]
    }
   ],
   "source": [
    "def preprocess_essays(df):\n",
    "    df['essay'] = df['project_essay_1'].map(str) +\\\n",
    "                  df['project_essay_2'].map(str) +\\\n",
    "                  df['project_essay_3'].map(str) +\\\n",
    "                  df['project_essay_4'].map(str)\n",
    "\n",
    "    df['essay'] = preprocess_text(df['essay'].values)\n",
    "    \n",
    "preprocess_essays(X_train)\n",
    "preprocess_essays(X_test)\n",
    "\n",
    "bow_model = CountVectorizer(min_df=10, max_features=10000)\n",
    "bow_model.fit(X_train['essay'].values)\n",
    "\n",
    "X_train_essay_bow = bow_model.transform(X_train['essay'].values)\n",
    "X_test_essay_bow = bow_model.transform(X_test['essay'].values)\n",
    "\n",
    "feature_list_bow.extend(bow_model.get_feature_names())\n",
    "\n",
    "print(X_train_essay_bow.shape, y_train.shape)\n",
    "print(X_test_essay_bow.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 5000) (20000,)\n",
      "(5000, 5000) (5000,)\n"
     ]
    }
   ],
   "source": [
    "tfidf_model = TfidfVectorizer(min_df=10, max_features=5000)\n",
    "tfidf_model.fit(X_train['essay'].values)\n",
    "\n",
    "X_train_essay_tfidf = tfidf_model.transform(X_train['essay'].values)\n",
    "X_test_essay_tfidf = tfidf_model.transform(X_test['essay'].values)\n",
    "\n",
    "print(X_train_essay_tfidf.shape, y_train.shape)\n",
    "print(X_test_essay_tfidf.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('glove_vectors', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "    glove_words = set(model.keys())\n",
    "\n",
    "tfidf_model = TfidfVectorizer()\n",
    "tfidf_model.fit(X_train['essay'])\n",
    "dictionary = dict(zip(tfidf_model.get_feature_names(), list(tfidf_model.idf_)))\n",
    "tfidf_words = set(tfidf_model.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "063f9bb8cc884e4581ce98c68da26e74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf_w2v_vectors_train = []\n",
    "for sentence in tqdm_notebook(X_train['essay'].values):\n",
    "    vector = np.zeros(300)\n",
    "    tf_idf_weight = 0\n",
    "    for word in sentence.split():\n",
    "        if (word in glove_words) and (word in tfidf_words):\n",
    "            vec = model[word]\n",
    "            tf_idf = dictionary[word]*(sentence.count(word)/len(sentence.split()))\n",
    "            vector += (vec * tf_idf)\n",
    "            tf_idf_weight += tf_idf\n",
    "    if tf_idf_weight != 0:\n",
    "        vector /= tf_idf_weight\n",
    "    tfidf_w2v_vectors_train.append(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b48a1e22d65a4ae395f79b988a49f298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf_w2v_vectors_test = []\n",
    "for sentence in tqdm_notebook(X_test['essay'].values):\n",
    "    vector = np.zeros(300)\n",
    "    tf_idf_weight = 0\n",
    "    for word in sentence.split():\n",
    "        if (word in glove_words) and (word in tfidf_words):\n",
    "            vec = model[word]\n",
    "            tf_idf = dictionary[word]*(sentence.count(word)/len(sentence.split()))\n",
    "            vector += (vec * tf_idf)\n",
    "            tf_idf_weight += tf_idf\n",
    "    if tf_idf_weight != 0:\n",
    "        vector /= tf_idf_weight\n",
    "    tfidf_w2v_vectors_test.append(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 300)\n",
      "(5000, 300)\n"
     ]
    }
   ],
   "source": [
    "X_train_tfidf_w2v = pd.DataFrame(tfidf_w2v_vectors_train)\n",
    "X_test_tfidf_w2v = pd.DataFrame(tfidf_w2v_vectors_test)\n",
    "\n",
    "print(X_train_tfidf_w2v.shape)\n",
    "print(X_test_tfidf_w2v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 1) (20000,)\n",
      "(5000, 1) (20000,)\n"
     ]
    }
   ],
   "source": [
    "normalizer = Normalizer()\n",
    "normalizer.fit(X_train['price'].values.reshape(1,-1))\n",
    "\n",
    "X_train_price_temp = normalizer.transform(X_train['price'].values.reshape(1,-1))\n",
    "X_test_price_temp = normalizer.transform(X_test['price'].values.reshape(1,-1))\n",
    "\n",
    "X_train_price_normalized = X_train_price_temp.reshape(-1,1)\n",
    "X_test_price_normalized = X_test_price_temp.reshape(-1,1)\n",
    "\n",
    "feature_list_bow.append('Price')\n",
    "feature_list_tfidf.append('Price')\n",
    "\n",
    "print(X_train_price_normalized.shape, y_train.shape)\n",
    "print(X_test_price_normalized.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. teacher_number_of_previously_posted_projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 1) (20000,)\n",
      "(5000, 1) (20000,)\n"
     ]
    }
   ],
   "source": [
    "normalizer = Normalizer()\n",
    "normalizer.fit(X_train['teacher_number_of_previously_posted_projects'].values.reshape(1,-1))\n",
    "\n",
    "X_train_price_temp = normalizer.transform(X_train['teacher_number_of_previously_posted_projects'].values.reshape(1,-1))\n",
    "X_test_price_temp = normalizer.transform(X_test['teacher_number_of_previously_posted_projects'].values.reshape(1,-1))\n",
    "\n",
    "X_train_prev_proj_norm = X_train_price_temp.reshape(-1,1)\n",
    "X_test_prev_proj_norm = X_test_price_temp.reshape(-1,1)\n",
    "\n",
    "feature_list_bow.append('teacher_number_of_previously_posted_projects')\n",
    "feature_list_tfidf.append('teacher_number_of_previously_posted_projects')\n",
    "\n",
    "print(X_train_prev_proj_norm.shape, y_train.shape)\n",
    "print(X_test_prev_proj_norm.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. sentiment_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 4)\n",
      "(5000, 4)\n"
     ]
    }
   ],
   "source": [
    "def sentiment_analyzer(col):\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    sentiment = analyzer.polarity_scores(col)\n",
    "    return list(sentiment.values())\n",
    "\n",
    "X_train_sentiment_temp = list(X_train['essay'].apply(sentiment_analyzer))\n",
    "X_test_sentiment_temp = list(X_test['essay'].apply(sentiment_analyzer))\n",
    "\n",
    "X_train_sentiment = pd.DataFrame(X_train_sentiment_temp, columns=['neg', 'neu', 'pos', 'compound'])\n",
    "X_test_sentiment = pd.DataFrame(X_test_sentiment_temp, columns=['neg', 'neu', 'pos', 'compound'])\n",
    "\n",
    "print(X_train_sentiment.shape)\n",
    "print(X_test_sentiment.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 8777) (20000,)\n",
      "(5000, 8777) (5000,)\n"
     ]
    }
   ],
   "source": [
    "# BOW without sentiment score\n",
    "X_train_bow = hstack((X_train_teacher_ohe, \\\n",
    "                      X_train_state_ohe, \\\n",
    "                      X_train_grade_ohe, \\\n",
    "                      X_train_subject_ohe, \\\n",
    "                      X_train_subject_subcategories_ohe, \\\n",
    "                      X_train_essay_bow, \\\n",
    "                      X_train_price_normalized, \\\n",
    "                      X_train_prev_proj_norm)).tocsr()\n",
    "\n",
    "X_test_bow = hstack((X_test_teacher_ohe, \\\n",
    "                     X_test_state_ohe, \\\n",
    "                     X_test_grade_ohe, \\\n",
    "                     X_test_subject_ohe, \\\n",
    "                     X_test_subject_subcategories_ohe, \\\n",
    "                     X_test_essay_bow, \\\n",
    "                     X_test_price_normalized, \\\n",
    "                     X_test_prev_proj_norm)).tocsr()\n",
    "\n",
    "print(X_train_bow.shape, y_train.shape)\n",
    "print(X_test_bow.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse.save_npz('X_train_bow', X_train_bow)\n",
    "sparse.save_npz('X_test_bow', X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 5408) (20000,)\n",
      "(5000, 5408) (5000,)\n"
     ]
    }
   ],
   "source": [
    "# TFIDF without sentiment score\n",
    "X_train_tfidf = hstack((X_train_teacher_ohe, \\\n",
    "                        X_train_state_ohe, \\\n",
    "                        X_train_grade_ohe, \\\n",
    "                        X_train_subject_ohe, \\\n",
    "                        X_train_subject_subcategories_ohe, \\\n",
    "                        X_train_essay_tfidf, \\\n",
    "                        X_train_price_normalized, \\\n",
    "                        X_train_prev_proj_norm)).tocsr()\n",
    "\n",
    "X_test_tfidf = hstack((X_test_teacher_ohe, \\\n",
    "                        X_test_state_ohe, \\\n",
    "                        X_test_grade_ohe, \\\n",
    "                        X_test_subject_ohe, \\\n",
    "                        X_test_subject_subcategories_ohe, \\\n",
    "                        X_test_essay_tfidf, \\\n",
    "                        X_test_price_normalized, \\\n",
    "                        X_test_prev_proj_norm)).tocsr()\n",
    "\n",
    "print(X_train_tfidf.shape, y_train.shape)\n",
    "print(X_test_tfidf.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse.save_npz('X_train_tfidf', X_train_tfidf)\n",
    "sparse.save_npz('X_test_tfidf', X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 5412) (20000,)\n",
      "(5000, 5412) (5000,)\n"
     ]
    }
   ],
   "source": [
    "# TFIDF with sentiment score\n",
    "X_train_tfidf_sc = hstack((X_train_teacher_ohe, \\\n",
    "                        X_train_state_ohe, \\\n",
    "                        X_train_grade_ohe, \\\n",
    "                        X_train_subject_ohe, \\\n",
    "                        X_train_subject_subcategories_ohe, \\\n",
    "                        X_train_essay_tfidf, \\\n",
    "                        X_train_price_normalized, \\\n",
    "                        X_train_prev_proj_norm, \\\n",
    "                        X_train_sentiment)).tocsr()\n",
    "\n",
    "X_test_tfidf_sc = hstack((X_test_teacher_ohe, \\\n",
    "                        X_test_state_ohe, \\\n",
    "                        X_test_grade_ohe, \\\n",
    "                        X_test_subject_ohe, \\\n",
    "                        X_test_subject_subcategories_ohe, \\\n",
    "                        X_test_essay_tfidf, \\\n",
    "                        X_test_price_normalized, \\\n",
    "                        X_test_prev_proj_norm, \\\n",
    "                        X_test_sentiment)).tocsr()\n",
    "\n",
    "print(X_train_tfidf_sc.shape, y_train.shape)\n",
    "print(X_test_tfidf_sc.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse.save_npz('X_train_tfidf_sc', X_train_tfidf_sc)\n",
    "sparse.save_npz('X_test_tfidf_sc', X_test_tfidf_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 712) (20000,)\n",
      "(5000, 712) (5000,)\n"
     ]
    }
   ],
   "source": [
    "# TFIDF W2V with sentiment score\n",
    "X_train_tfidf_w2v_sc = hstack((X_train_teacher_ohe, \\\n",
    "                        X_train_state_ohe, \\\n",
    "                        X_train_grade_ohe, \\\n",
    "                        X_train_subject_ohe, \\\n",
    "                        X_train_subject_subcategories_ohe, \\\n",
    "                        X_train_tfidf_w2v, \\\n",
    "                        X_train_price_normalized, \\\n",
    "                        X_train_prev_proj_norm, \\\n",
    "                        X_train_sentiment)).tocsr()\n",
    "\n",
    "X_test_tfidf_w2v_sc = hstack((X_test_teacher_ohe, \\\n",
    "                        X_test_state_ohe, \\\n",
    "                        X_test_grade_ohe, \\\n",
    "                        X_test_subject_ohe, \\\n",
    "                        X_test_subject_subcategories_ohe, \\\n",
    "                        X_test_tfidf_w2v, \\\n",
    "                        X_test_price_normalized, \\\n",
    "                        X_test_prev_proj_norm, \\\n",
    "                        X_test_sentiment)).tocsr()\n",
    "\n",
    "print(X_train_tfidf_w2v_sc.shape, y_train.shape)\n",
    "print(X_test_tfidf_w2v_sc.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse.save_npz('X_train_tfidf_w2v_sc', X_train_tfidf_sc)\n",
    "sparse.save_npz('X_test_tfidf_w2v_sc', X_test_tfidf_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 5016) (20000,)\n",
      "(5000, 5016) (5000,)\n"
     ]
    }
   ],
   "source": [
    "# TFIDF Response coded\n",
    "X_train_tfidf_rc = hstack((teacher_prefix_train_df, \\\n",
    "                        school_state_train_df, \\\n",
    "                        project_grade_category_train_df, \\\n",
    "                        project_subject_categories_train_df, \\\n",
    "                        project_subject_subcategories_train_df, \\\n",
    "                        X_train_essay_tfidf, \\\n",
    "                        X_train_price_normalized, \\\n",
    "                        X_train_prev_proj_norm, \\\n",
    "                        X_train_sentiment)).tocsr()\n",
    "\n",
    "X_test_tfidf_rc = hstack((teacher_prefix_test_df, \\\n",
    "                        school_state_test_df, \\\n",
    "                        project_grade_category_test_df, \\\n",
    "                        project_subject_categories_test_df, \\\n",
    "                        project_subject_subcategories_test_df, \\\n",
    "                        X_test_essay_tfidf, \\\n",
    "                        X_test_price_normalized, \\\n",
    "                        X_test_prev_proj_norm, \\\n",
    "                        X_test_sentiment)).tocsr()\n",
    "\n",
    "print(X_train_tfidf_rc.shape, y_train.shape)\n",
    "print(X_test_tfidf_rc.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse.save_npz('X_train_tfidf_rc', X_train_tfidf_rc)\n",
    "sparse.save_npz('X_test_tfidf_rc', X_test_tfidf_rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 316) (20000,)\n",
      "(5000, 316) (5000,)\n"
     ]
    }
   ],
   "source": [
    "# TFIDF W2V Response coded\n",
    "X_train_tfidf_w2v_rc = hstack((teacher_prefix_train_df, \\\n",
    "                            school_state_train_df, \\\n",
    "                            project_grade_category_train_df, \\\n",
    "                            project_subject_categories_train_df, \\\n",
    "                            project_subject_subcategories_train_df, \\\n",
    "                            X_train_tfidf_w2v, \\\n",
    "                            X_train_price_normalized, \\\n",
    "                            X_train_prev_proj_norm, \\\n",
    "                            X_train_sentiment)).tocsr()\n",
    "\n",
    "X_test_tfidf_w2v_rc = hstack((teacher_prefix_test_df, \\\n",
    "                            school_state_test_df, \\\n",
    "                            project_grade_category_test_df, \\\n",
    "                            project_subject_categories_test_df, \\\n",
    "                            project_subject_subcategories_test_df, \\\n",
    "                            X_test_tfidf_w2v, \\\n",
    "                            X_test_price_normalized, \\\n",
    "                            X_test_prev_proj_norm, \\\n",
    "                            X_test_sentiment)).tocsr()\n",
    "\n",
    "print(X_train_tfidf_w2v_rc.shape, y_train.shape)\n",
    "print(X_test_tfidf_w2v_rc.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse.save_npz('X_train_tfidf_w2v_rc', X_train_tfidf_w2v_rc)\n",
    "sparse.save_npz('X_test_tfidf_w2v_rc', X_test_tfidf_w2v_rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('y_train', y_train)\n",
    "np.save('y_test', y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
